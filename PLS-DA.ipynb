{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9425aaea",
   "metadata": {},
   "source": [
    "# PLS-DA analysis tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f857ba",
   "metadata": {},
   "source": [
    "### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, RocCurveDisplay, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cab412",
   "metadata": {},
   "source": [
    "### Load the example dataset using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ffcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcMSData = pds.read_csv('./Data/Dementia_RPOS_XCMS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the retention time and m/z value from feature names\n",
    "featuresData = pds.DataFrame([(float(x.split('_')[0]), float(x.split('_')[1][:-3])) for x in lcMSData.columns[11:]], columns=['Rt', 'mz'])\n",
    "featuresData['Rt'] = featuresData['Rt']/60\n",
    "medianSpectrum = np.median(lcMSData.iloc[:, 11:].values, axis=0)\n",
    "\n",
    "# Use log of median spectra as intensity value for the scatterplot\n",
    "featuresData['Median'] = np.log(medianSpectrum + 1)\n",
    "#featuresData['Median'] = medianSpectrum "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9cb5e6",
   "metadata": {},
   "source": [
    "## PLS-DA model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b2dda",
   "metadata": {},
   "source": [
    "The first step in a PLS-DA model is to fit a PLS regression model with a dummy vector/matrix encoding class membership as Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555597e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the MS features\n",
    "XDataMatrix = lcMSData.iloc[:, 11:].values\n",
    "\n",
    "# Log transform the data matrix \n",
    "logXDataMatrix = np.log(XDataMatrix + 1)\n",
    "\n",
    "YGender = pds.Categorical(lcMSData['Gender'].values)\n",
    "YGenderDummy = pds.Categorical(YGender).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas Categorical object associates the \"categories\" text name with a numerical code\n",
    "# The numerical code follows the order in the .categories index\n",
    "YGender.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee11ec9",
   "metadata": {},
   "source": [
    "The YGenderDummy vector is now a vector of 0s and 1s, where 0=Female and 1=Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2cbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "YGenderDummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d818a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular apply PLS with dummy vector as Y\n",
    "plsModel = Pipeline(steps=[('uv_scale', StandardScaler()), ('PLS', PLSRegression(n_components=2, scale=False))])\n",
    "\n",
    "plsModel.fit(logXDataMatrix, YGenderDummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48244d1e",
   "metadata": {},
   "source": [
    "### PLS-DA model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635284b9",
   "metadata": {},
   "source": [
    "The predictions of a PLS regression model is a continuous value. To convert this number into a class prediction, we need an extra classification rule or algorithm. The simplest procedure is to assign the class membership which is closest to the predicted value. For example, the class will be 0 (Female) if prediction < 0.5, or Male if > 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictFrame = pds.DataFrame(np.c_[plsModel.predict(logXDataMatrix), YGenderDummy], columns=['Predicted', 'Gender'])\n",
    "\n",
    "fig = px.scatter(predictFrame, x=\"Predicted\", y=\"Gender\", render_mode='webgl', \n",
    "                labels={\"Predicted\": \"PLS predicted Gender\",\n",
    "                        \"Gender\": \"Gender\"}, \n",
    "                template='plotly_white')\n",
    "\n",
    "fig.add_vline(x=0.5, line_dash=\"dash\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a7912",
   "metadata": {},
   "source": [
    "We will instead convert the PLS outputs into a class prediction using a logistic regression model. The class will be predicted with the logistic regression model using the PLS T-scores (class ~ PLS scores). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "daModel = LogisticRegression()\n",
    "\n",
    "plsScores = plsModel.transform(X=logXDataMatrix)\n",
    "\n",
    "# Fit the logistic regression model with the scores\n",
    "daModel.fit(plsScores, YGenderDummy)\n",
    "\n",
    "# Obtain the test set scores and the prediction\n",
    "plsDaClassification = daModel.predict(plsScores)\n",
    "\n",
    "# ROC curve \n",
    "RocCurveDisplay.from_estimator(daModel, X=plsScores, y=YGenderDummy)\n",
    "\n",
    "# Score ROC AUC\n",
    "\"ROC AUC: {0}\".format(roc_auc_score(plsDaClassification, YGenderDummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c7faa",
   "metadata": {},
   "source": [
    "_The model seems to perform very well..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187de27",
   "metadata": {},
   "source": [
    "### PLS-DA scores plot\n",
    "Lets's now examine the PLS scores plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7acd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_scores = plsModel.transform(logXDataMatrix)\n",
    "\n",
    "# Assemble a pandas data frame with the scores for each component and then combine with study variables\n",
    "plsResultsDFrame = pds.DataFrame(T_scores, columns=['PLS T' + str(x+1) for x in range(T_scores.shape[1])])\n",
    "plsResultsDFrame = pds.concat([lcMSData.loc[:, ['Subject ID', 'Sample ID', 'Age', 'Gender', 'Run Order', 'Acquisition batch']], plsResultsDFrame], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece79e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(plsResultsDFrame, x=\"PLS T1\", y=\"PLS T2\", color=\"Gender\",\n",
    "                 render_mode='webgl', \n",
    "                template='plotly_white')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55afd5",
   "metadata": {},
   "source": [
    "The PLS parameters are exactly the same as those in the PLS regression - see the PLS tutorial for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7794041",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(featuresData, x=\"Rt\", y=\"mz\", color=plsModel['PLS'].x_weights_[:, 0], render_mode='webgl', \n",
    "                color_continuous_scale='RdBu', color_continuous_midpoint=0,\n",
    "                labels={\"Rt\": \"Retention time (min)\",\n",
    "                        \"mz\": \"m/z\"}, \n",
    "                template='plotly_white')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f437c",
   "metadata": {},
   "source": [
    "### Model validation and overfitting\n",
    "\n",
    "The model ROC curve and ROC AUC values we obtained were very good (ROC AUC > 0.95)!!\n",
    "But can we trust the discrimination results we obtained? Is PLS that prone to overfitting and over-optimism?\n",
    "\n",
    "Lets do a simple test: refit a model with a random Y vector..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62556a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random resampling of the original Y vector\n",
    "YGenderFake = np.random.choice(YGenderDummy, size=len(YGenderDummy))\n",
    "\n",
    "plsModel = Pipeline(steps=[('uv_scale', StandardScaler()), ('PLS', PLSRegression(n_components=2, scale=False))])\n",
    "\n",
    "plsModel.fit(logXDataMatrix, YGenderFake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2305e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictFrame = pds.DataFrame(np.c_[plsModel.predict(logXDataMatrix), YGenderFake], columns=['Predicted', 'Gender'])\n",
    "\n",
    "fig = px.scatter(predictFrame, x=\"Predicted\", y=\"Gender\", render_mode='webgl', \n",
    "                labels={\"Predicted\": \"PLS predicted Gender\",\n",
    "                        \"Gender\": \"Gender\"}, \n",
    "                template='plotly_white')\n",
    "\n",
    "fig.add_vline(x=0.5, line_dash=\"dash\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_scores = plsModel.transform(logXDataMatrix)\n",
    "\n",
    "GenderFakeColumn = pds.Series(YGenderFake).map({0:'Female', 1:'Male'})\n",
    "# Assemble a pandas data frame with the scores for each component and then combine with study variables\n",
    "plsResultsDFrame = pds.DataFrame(T_scores, columns=['PLS' + str(x+1) for x in range(T_scores.shape[1])])\n",
    "plsResultsDFrame = pds.concat([lcMSData.loc[:, ['Subject ID', 'Sample ID', 'Age', 'Gender', 'Run Order', 'Acquisition batch']], pds.Series(GenderFakeColumn, name='GenderFake'), plsResultsDFrame], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(plsResultsDFrame, x=\"PLS1\", y=\"PLS2\", color=\"GenderFake\",\n",
    "                 render_mode='webgl', \n",
    "                template='plotly_white')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeae04f",
   "metadata": {},
   "source": [
    "... and this is why PLS scores plots cannot be trusted to check a model quality. Separation in a PLS score plot is **NOT** a good measure of model quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15101186",
   "metadata": {},
   "source": [
    "### Model cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd7438",
   "metadata": {},
   "source": [
    "Instead, we will use cross-validation to obtain reliable model performance estimates. \n",
    "\n",
    "The following code uses a stratified (preserving the % prevalence of each class in the test set) K-Fold cross-validation routine to obtain ROC AUC, f1-score, and r-squared values which were calculated on external test set data (data not used to fit the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c31235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to fit and cross-validate a PLS-DA model\n",
    "def crossValidate_PLSDA(x, y, n_components=2, scale=True, cv=StratifiedKFold(7)):\n",
    "    \n",
    "    if scale is True:\n",
    "        plsModel = Pipeline(steps=[('uv_scale', StandardScaler()), \n",
    "                                   ('PLS', PLSRegression(n_components=n_components, scale=False))])\n",
    "    else:\n",
    "        plsModel = Pipeline(steps=[('PLS', PLSRegression(n_components=n_components, scale=False))])\n",
    "        \n",
    "    daModel = LogisticRegression()\n",
    "\n",
    "    cvResults = {'roc_auc':[], 'f1':[], 'r2':[]}\n",
    "\n",
    "    # Iterate through CV rounds\n",
    "    for trainIdx, testIdx in cv.split(x, y):\n",
    "        \n",
    "        # Fit the PLS model on training set\n",
    "        plsModel.fit(x[trainIdx, :], y[trainIdx])\n",
    "        \n",
    "        cvResults['r2'].append(r2_score(y[testIdx], plsModel.predict(x[testIdx, :])))\n",
    "        # Obtain the scores from the training set\n",
    "        plsTrainScores = plsModel.transform(X=x[trainIdx, :])\n",
    "        # Fit the QDA model with the train set scores and Y train set\n",
    "        daModel.fit(plsTrainScores, y[trainIdx])\n",
    "        \n",
    "        # Obtain the test set scores and the prediction\n",
    "        plsTestScores = plsModel.transform(X=x[testIdx, :])\n",
    "        testPredicted = daModel.predict(plsTestScores)\n",
    "        \n",
    "        # Score ROC AUC\n",
    "        cvResults['roc_auc'].append(roc_auc_score(testPredicted, y[testIdx]))\n",
    "        cvResults['f1'].append(f1_score(testPredicted, y[testIdx]))\n",
    "        # cvResults['roc'].append(roc_curve(YGender[testIdx], qdaModel.predict_proba(plsTestScores)[:,0]))\n",
    "        \n",
    "    cvResults = {key: np.array(value) for key, value in cvResults.items()}\n",
    "    return pds.DataFrame(cvResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvResults = crossValidate_PLSDA(logXDataMatrix, YGenderDummy, n_components=2, scale=True, cv=StratifiedKFold(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd89c5",
   "metadata": {},
   "source": [
    "The result of the 7-Fold CV process is 7 instances of the classifier performance metrics chosen (roc_auc, f1, r2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3564b44a",
   "metadata": {},
   "source": [
    "### Selecting the optimal number of components with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f3867",
   "metadata": {},
   "source": [
    "Cross-validation should also be used to select the optimal number of components. The CV procedure should be applied to models with a varying number of components, to generate a \"scree plot\" with cross-validated measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNComponents = 10\n",
    "\n",
    "screePLSDA = [crossValidate_PLSDA(logXDataMatrix, YGenderDummy, n_components=x, scale=True, cv=StratifiedKFold(7)) for x in range(1, maxNComponents + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e1c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvPLSDA_DFrame = list()\n",
    "\n",
    "for ncomp, cv in enumerate(screePLSDA):\n",
    "    currentNComp = pds.DataFrame(cv)\n",
    "    currentNComp['Ncomp'] = ncomp + 1\n",
    "    cvPLSDA_DFrame.append(currentNComp)\n",
    "    \n",
    "cvPLSDA_DFrame = pds.concat(cvPLSDA_DFrame, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afc26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(cvPLSDA_DFrame, x='Ncomp', y='roc_auc', # points=\"all\",\n",
    "             labels={\"Ncomp\": \"Number of components\",\n",
    "                        \"auc\": \"ROC AUC\"}, template='plotly_white')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d999f",
   "metadata": {},
   "source": [
    "The gains in model performance after 4 components become marginal, and therefore we will select 4 as the optimal number of components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577fb4f1",
   "metadata": {},
   "source": [
    "### Fit model with optimal number of PLS components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plsModel = Pipeline(steps=[('uv_scale', StandardScaler()), \n",
    "                                   ('PLS', PLSRegression(n_components=4, scale=False))])\n",
    "\n",
    "daModel = LogisticRegression()\n",
    "\n",
    "# Fit the PLS-DA model to the full dataset\n",
    "plsModel.fit(logXDataMatrix, YGenderDummy)\n",
    "daModel.fit(plsModel.transform(logXDataMatrix), YGenderDummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47970be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvResults = crossValidate_PLSDA(logXDataMatrix, YGenderDummy, n_components=4, scale=True, cv=StratifiedKFold(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c53e9b",
   "metadata": {},
   "source": [
    "These cross-validated metrics are better estimates of the expected model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a32a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds.DataFrame(np.c_[cvResults.mean(), cvResults.std()], columns=['Mean', 'Stdev'], index=cvResults.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5003009",
   "metadata": {},
   "source": [
    "### Permutation randomisation test\n",
    "\n",
    "A final and very important method for model validation is the permutation randomization test. In a permutation randomisation test, the model will be refitted and assessed multiple times, but each time with the Y randomly permuted to destroy any relationship between X & Y. This allows us to assess what sort of model we can get when there really is no relationship between the two data matrices, and calculate the likelihood of obtaining a model with predictive performance as good as the non-permuted model by chance alone.\n",
    "\n",
    "During this test, the number of components, scaling, type of cross-validation employed, and any other modeling choice is kept constant. In each randomization, the model is refitted, and the performance and model validation metric recorded. This enables the generation of permuted null distributions for these metrics, which can be used to obtain an empirical p-value for their significance.\n",
    "\n",
    "**Note**: Running the permutation test with a large number of permutation randomizations (for example, 1000) is expected to take a considerable ammount of time (> 30 mins on a laptop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nPermutations = 50\n",
    "\n",
    "permResults = []\n",
    "\n",
    "for permutation in range(nPermutations):\n",
    "        # permute the Y vector\n",
    "        permutedY = np.random.permutation(YGenderDummy)\n",
    "        # Select the same number of components, and apply cross-validation in the same manner\n",
    "        permcvResults = crossValidate_PLSDA(logXDataMatrix, permutedY, n_components=4, scale=True, cv=StratifiedKFold(7))\n",
    "        permResults.append(permcvResults.mean())\n",
    "\n",
    "permResults = pds.DataFrame(permResults)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b0e440",
   "metadata": {},
   "source": [
    "Histogram of results from permuted (null) models. The vertical line represents the ROC AUC value obtained in the \"real\" model. **Note**: The numerical precision of the p-value estimate is dependent on the number of permutations used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(permResults, x='roc_auc', nbins=20)\n",
    "\n",
    "fig.add_vline(x=cvResults['roc_auc'].mean(), line_dash=\"dash\")\n",
    "fig.show()\n",
    "\"Permutation p-value ~ {0}\".format(np.sum(permResults['roc_auc'] >= cvResults['roc_auc'].mean())/(nPermutations + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e5a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
